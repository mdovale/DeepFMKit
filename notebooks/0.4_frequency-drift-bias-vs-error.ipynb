{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4130766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepFMKit.workers import run_single_trial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import scipy.constants as sc\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "def generate_error_budget_plot_hybrid_parallel(\n",
    "    m_true=15.5,\n",
    "    ndata=15,\n",
    "    f0=193.55e12,\n",
    "    delta_f=3e9,\n",
    "    T_acq_range=np.logspace(0, 4, 6),\n",
    "    n_trials=1000,\n",
    "    amp_asd=1e-5,\n",
    "    freq_asd=1e3,\n",
    "    T_base_stat=0.1,\n",
    "    n_cores=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates the DFMI error budget plot using a hybrid parallel strategy.\n",
    "\n",
    "    This function efficiently calculates and visualizes the trade-off between\n",
    "    statistical and systematic errors. For the systematic error from laser\n",
    "    drift, it calculates and plots both the mean bias and the standard\n",
    "    deviation of the bias over many trials. This provides a complete picture\n",
    "    of the error's behavior.\n",
    "\n",
    "    The method uses three key techniques:\n",
    "    1.  It characterizes a baseline statistical error at a short acquisition\n",
    "        time (`T_base_stat`) via a parallel Monte Carlo simulation.\n",
    "    2.  It analytically extrapolates this baseline error to all other\n",
    "        acquisition times using the known `1/sqrt(T)` scaling of white noise.\n",
    "    3.  It uses a parallelized hybrid simulation for laser drift, modeling\n",
    "        the low-frequency drift accumulation over long times and injecting its\n",
    "        characteristic distortion into short, high-rate signals for fitting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    m_true : float, optional\n",
    "        The ground-truth modulation depth to test.\n",
    "    ndata : int, optional\n",
    "        The number of harmonics to use in the fit.\n",
    "    f0 : float, optional\n",
    "        The laser carrier frequency in Hz.\n",
    "    delta_f : float, optional\n",
    "        The laser frequency modulation amplitude in Hz.\n",
    "    T_acq_range : array_like, optional\n",
    "        The range of acquisition times (in seconds) to simulate.\n",
    "    n_trials : int, optional\n",
    "        The number of Monte Carlo trials to run for each simulation point.\n",
    "    amp_asd : float, optional\n",
    "        The ASD of the white amplitude noise.\n",
    "    freq_asd : float,optional\n",
    "        The ASD of the 1/f laser frequency noise at 1 Hz.\n",
    "    T_base_stat : float, optional\n",
    "        The fixed, short acquisition time (in seconds) used to establish the\n",
    "        baseline statistical uncertainty.\n",
    "    n_cores : int, optional\n",
    "        Number of CPU cores to use. If None, uses all available cores.\n",
    "    \"\"\"\n",
    "    if n_cores is None:\n",
    "        n_cores = os.cpu_count()\n",
    "        print(f\"Using all available {n_cores} CPU cores.\")\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Generating Error Budget Plot (Hybrid Parallel Version)\")\n",
    "    print(f\"Parameters: m_true={m_true}, n_trials={n_trials}, n_cores={n_cores}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # --- 1. Characterize BASELINE Statistical Error ---\n",
    "    print(f\"\\nCharacterizing baseline statistical error at T_acq = {T_base_stat} s...\")\n",
    "    job_params_base = [{\n",
    "        'trial_num': i, 'sim_type': 'stat_base', 'T_acq': 0, 'T_base': T_base_stat,\n",
    "        'm_true': m_true, 'delta_f': delta_f, 'amp_asd': amp_asd,\n",
    "        'freq_asd': freq_asd, 'ndata': ndata\n",
    "    } for i in range(n_trials)]\n",
    "\n",
    "    with multiprocessing.Pool(processes=n_cores) as pool:\n",
    "        desc = f\"Base Stat Trials (T={T_base_stat}s)\"\n",
    "        results_iterator = pool.imap(run_single_trial, job_params_base)\n",
    "        m_fits_base = list(tqdm(results_iterator, total=n_trials, desc=desc))\n",
    "\n",
    "    m_std_base = np.std(m_fits_base)\n",
    "    print(f\"--> Baseline statistical uncertainty (std dev of m) = {m_std_base:.3e}\")\n",
    "\n",
    "    # --- 2. Build the two error curves over the full T_acq range ---\n",
    "    # Prepare lists to store the results for each T_acq\n",
    "    delta_m_stat_list = []\n",
    "    mean_m_sys_list = []\n",
    "    std_m_sys_list = []\n",
    "    m_to_phi_factor = f0 / delta_f\n",
    "\n",
    "    for T_acq in T_acq_range:\n",
    "        print(f\"\\nProcessing T_acq = {T_acq:.4f} s...\")\n",
    "\n",
    "        # A) EXTRAPOLATE Statistical Error (fast, no simulation needed)\n",
    "        delta_m_stat = m_std_base * np.sqrt(T_base_stat / T_acq)\n",
    "        delta_m_stat_list.append(delta_m_stat)\n",
    "        print(f\"  --> Extrapolated stat error (m): {delta_m_stat:.3e}\")\n",
    "\n",
    "        # B) RUN HYBRID SIMULATION for Systematic Error (parallelized)\n",
    "        job_params_sys = [{\n",
    "            'trial_num': i, 'sim_type': 'sys_hybrid', 'T_acq': T_acq, 'T_base': 0,\n",
    "            'm_true': m_true, 'delta_f': delta_f, 'amp_asd': amp_asd,\n",
    "            'freq_asd': freq_asd, 'ndata': ndata\n",
    "        } for i in range(n_trials)]\n",
    "\n",
    "        with multiprocessing.Pool(processes=n_cores) as pool:\n",
    "            desc = f\"Sys Hybrid Trials (T={T_acq:.2f}s)\"\n",
    "            results_iterator = pool.imap(run_single_trial, job_params_sys)\n",
    "            biases_sys = list(tqdm(results_iterator, total=n_trials, desc=desc))\n",
    "        \n",
    "        # Calculate both mean and standard deviation of the bias\n",
    "        mean_m_sys_list.append(np.mean(biases_sys))\n",
    "        std_m_sys_list.append(np.std(biases_sys))\n",
    "        print(f\"  --> Hybrid systematic error (m): mean={np.mean(biases_sys):.3e}, std={np.std(biases_sys):.3e}\")\n",
    "\n",
    "    # --- 3. Analysis and Plotting ---\n",
    "    print(\"\\nSimulation complete. Generating plot...\")\n",
    "    # Convert lists to numpy arrays\n",
    "    delta_m_stat_arr = np.array(delta_m_stat_list)\n",
    "    mean_m_sys_arr = np.array(mean_m_sys_list)\n",
    "    std_m_sys_arr = np.array(std_m_sys_list)\n",
    "\n",
    "    # Convert m errors to phase errors\n",
    "    delta_phi_stat = delta_m_stat_arr * m_to_phi_factor\n",
    "    delta_phi_sys_mean = mean_m_sys_arr * m_to_phi_factor\n",
    "    delta_phi_sys_std = std_m_sys_arr * m_to_phi_factor\n",
    "    \n",
    "    # Total error is the quadrature sum of the UNCERTAINTIES (standard deviations)\n",
    "    delta_phi_total = np.sqrt(delta_phi_stat**2 + delta_phi_sys_std**2)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Plot the statistical uncertainty\n",
    "    ax.loglog(T_acq_range, delta_phi_stat, 'o-', color='tab:blue', label=r'Statistical Error (Uncertainty)')\n",
    "    \n",
    "    # Plot the systematic uncertainty (std dev of bias)\n",
    "    ax.loglog(T_acq_range, delta_phi_sys_std, 's-', color='tab:red', label=r'Systematic Error from Drift (Std. Dev. of Bias)')\n",
    "\n",
    "    # Plot the systematic mean bias (should be near zero)\n",
    "    ax.loglog(T_acq_range, np.abs(delta_phi_sys_mean), 'x--', color='tab:purple', label=r'Systematic Error from Drift (Mean Bias)')\n",
    "    \n",
    "    # Plot the total error\n",
    "    ax.loglog(T_acq_range, delta_phi_total, 'k-', linewidth=3, label='Total Error (Quadrature Sum)')\n",
    "    \n",
    "    # Plot the ambiguity limit\n",
    "    ax.axhline(np.pi, color='k', linestyle='--', linewidth=2.5, label=r'Ambiguity Limit ($\\pi$)')\n",
    "\n",
    "    ax.set_xlabel(r'Acquisition Time, $T_{\\rm acq}$ (s)', fontsize=14)\n",
    "    ax.set_ylabel(r'Coarse Phase Error, $|\\delta\\Phi_{\\rm coarse}|$ (rad)', fontsize=14)\n",
    "    ax.set_title('DFMI Error Budget vs. Acquisition Time', fontsize=16)\n",
    "    ax.grid(True, which='both', linestyle=':')\n",
    "    \n",
    "    wavelength = sc.c / f0\n",
    "    phi_to_length_nm = (wavelength / (2 * np.pi)) * 1e9\n",
    "    ax2 = ax.twinx()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_ylim(ymin * phi_to_length_nm, ymax * phi_to_length_nm)\n",
    "    ax2.set_ylabel(r'Equivalent Length Error (nm)', fontsize=14)\n",
    "\n",
    "    # Find and mark the optimal point on the total error curve\n",
    "    min_error_idx = np.argmin(delta_phi_total)\n",
    "    optimal_T = T_acq_range[min_error_idx]\n",
    "    min_error = delta_phi_total[min_error_idx]\n",
    "    ax.plot(optimal_T, min_error, 'p', color='gold', markersize=15, markeredgecolor='black', label=f'Optimal Point ({optimal_T:.2f} s)')\n",
    "    \n",
    "    ax.legend(fontsize=12, loc='best')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_error_budget_plot_hybrid_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b76845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
